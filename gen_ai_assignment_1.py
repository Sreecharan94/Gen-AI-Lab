# -*- coding: utf-8 -*-
"""GEN AI ASSIGNMENT 1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NUKP6do5_SXLW6293kfOo-42ggv4e76J

QUESTION-1
"""

import torch, torch.nn as nn, torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])
train_loader = DataLoader(
    datasets.FashionMNIST("./data", train=True, transform=transform, download=True),
    batch_size=128, shuffle=True
)
labels_map = ["T-shirt", "Trouser", "Pullover", "Dress", "Coat",
              "Sandal", "Shirt", "Sneaker", "Bag", "Ankle boot"]

class Generator(nn.Module):
    def __init__(self, z_dim=100, n_classes=10, img_shape=(1,28,28)):
        super().__init__()
        self.embed = nn.Embedding(n_classes, n_classes)
        self.model = nn.Sequential(
            nn.Linear(z_dim+n_classes, 256), nn.LeakyReLU(0.2),
            nn.Linear(256,512), nn.BatchNorm1d(512), nn.LeakyReLU(0.2),
            nn.Linear(512,1024), nn.BatchNorm1d(1024), nn.LeakyReLU(0.2),
            nn.Linear(1024, int(torch.prod(torch.tensor(img_shape)))), nn.Tanh()
        )
        self.img_shape = img_shape
    def forward(self, z, labels):
        x = torch.cat([z, self.embed(labels)], 1)
        img = self.model(x).view(x.size(0), *self.img_shape)
        return img

class Discriminator(nn.Module):
    def __init__(self, n_classes=10, img_shape=(1,28,28)):
        super().__init__()
        self.embed = nn.Embedding(n_classes, n_classes)
        self.model = nn.Sequential(
            nn.Linear(n_classes+int(torch.prod(torch.tensor(img_shape))), 512), nn.LeakyReLU(0.2),
            nn.Linear(512,256), nn.LeakyReLU(0.2),
            nn.Linear(256,1), nn.Sigmoid()
        )
    def forward(self, img, labels):
        x = torch.cat([img.view(img.size(0), -1), self.embed(labels)], 1)
        return self.model(x)

z_dim, n_classes, img_shape = 100, 10, (1,28,28)
G, D = Generator(z_dim,n_classes,img_shape).to(device), Discriminator(n_classes,img_shape).to(device)
loss_fn = nn.BCELoss()
opt_G = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5,0.999))
opt_D = optim.Adam(D.parameters(), lr=0.0002, betas=(0.5,0.999))

epochs = 5
for epoch in range(epochs):
    for imgs, labels in train_loader:
        imgs, labels = imgs.to(device), labels.to(device)
        bsz = imgs.size(0)
        real, fake = torch.ones(bsz,1,device=device), torch.zeros(bsz,1,device=device)
        z = torch.randn(bsz,z_dim,device=device)
        gen_labels = torch.randint(0,n_classes,(bsz,),device=device)
        gen_imgs = G(z, gen_labels)

        d_loss = (loss_fn(D(imgs,labels), real) + loss_fn(D(gen_imgs.detach(),gen_labels), fake))/2
        opt_D.zero_grad(); d_loss.backward(); opt_D.step()

        g_loss = loss_fn(D(gen_imgs, gen_labels), real)
        opt_G.zero_grad(); g_loss.backward(); opt_G.step()

print(f"Epoch [{epoch+1}/{epochs}] D_loss: {d_loss:.4f}, G_loss: {g_loss:.4f}")

G.eval()
z = torch.randn(10, z_dim, device=device)
labels = torch.arange(0,10,device=device)
gen_imgs = G(z, labels).cpu().detach()

plt.figure(figsize=(10,2))
for i in range(10):
    plt.subplot(1,10,i+1)
    plt.imshow(gen_imgs[i][0], cmap="gray")
    plt.title(labels_map[i], fontsize=8)
    plt.axis("off")
plt.show()