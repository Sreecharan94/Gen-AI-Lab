# -*- coding: utf-8 -*-
"""GEN AI ASSIGNMENT 2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vlarm5p44N_zBw2kaGaN0ks-yIT-2fYm

QUESTION 2
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])
dataset = datasets.FakeData(size=1000, image_size=(3,32,32), num_classes=10, transform=transform)
loader = DataLoader(dataset, batch_size=64, shuffle=True)

class Generator(nn.Module):
    def __init__(self, z_dim=100, img_channels=3):
        super().__init__()
        self.model = nn.Sequential(
            nn.ConvTranspose2d(z_dim,128,4,1,0,bias=False),
            nn.BatchNorm2d(128), nn.ReLU(True),
            nn.ConvTranspose2d(128,64,4,2,1,bias=False),
            nn.BatchNorm2d(64), nn.ReLU(True),
            nn.ConvTranspose2d(64,img_channels,4,2,1,bias=False),
            nn.Tanh()
        )
    def forward(self,z): return self.model(z)

class Discriminator(nn.Module):
    def __init__(self, img_channels=3):
        super().__init__()
        self.model = nn.Sequential(
            nn.Conv2d(img_channels,64,4,2,1,bias=False),
            nn.LeakyReLU(0.2,True),
            nn.Conv2d(64,128,4,2,1,bias=False),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2,True),
            nn.Conv2d(128,1,4,1,0,bias=False)
        )
        self.sigmoid = nn.Sigmoid()
    def forward(self,img):
        out = self.model(img)
        return self.sigmoid(out).view(img.size(0), -1).mean(1, keepdim=True)

z_dim = 100
G = Generator(z_dim).to(device)
D = Discriminator().to(device)
loss_fn = nn.BCELoss()
opt_G = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5,0.999))
opt_D = optim.Adam(D.parameters(), lr=0.0002, betas=(0.5,0.999))

epochs = 5
for epoch in range(epochs):
    for imgs, _ in loader:
        imgs = imgs.to(device)
        bsz = imgs.size(0)
        real, fake = torch.ones(bsz,1,device=device), torch.zeros(bsz,1,device=device)

        z = torch.randn(bsz,z_dim,1,1,device=device)
        gen_imgs = G(z)
        d_loss = (loss_fn(D(imgs),real)+loss_fn(D(gen_imgs.detach()),fake))/2
        opt_D.zero_grad(); d_loss.backward(); opt_D.step()

        g_loss = loss_fn(D(gen_imgs),real)
        opt_G.zero_grad(); g_loss.backward(); opt_G.step()

print(f"Epoch [{epoch+1}/{epochs}] D_loss:{d_loss:.4f} G_loss:{g_loss:.4f}")

G.eval()
z = torch.randn(16,z_dim,1,1,device=device)
gen_imgs = G(z).cpu().detach()

plt.figure(figsize=(6,6))
for i in range(16):
    plt.subplot(4,4,i+1)
    plt.imshow((gen_imgs[i].permute(1,2,0)+1)/2)
    plt.axis("off")
plt.show()

!pip install torch torchvision matplotlib

import torch, torch.nn as nn, torch.optim as optim
from torchvision import datasets, transforms, utils
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt, numpy as np

device = "cuda" if torch.cuda.is_available() else "cpu"

transform = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
    transforms.Normalize([0.5],[0.5])
])
dataset = datasets.CIFAR10(root="./data", train=True, transform=transform, download=True)
loader = DataLoader(dataset, batch_size=128, shuffle=True)

class Generator(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.ConvTranspose2d(100,512,4,1,0,bias=False), nn.BatchNorm2d(512), nn.ReLU(True),
            nn.ConvTranspose2d(512,256,4,2,1,bias=False), nn.BatchNorm2d(256), nn.ReLU(True),
            nn.ConvTranspose2d(256,128,4,2,1,bias=False), nn.BatchNorm2d(128), nn.ReLU(True),
            nn.ConvTranspose2d(128,64,4,2,1,bias=False), nn.BatchNorm2d(64), nn.ReLU(True),
            nn.ConvTranspose2d(64,3,4,2,1,bias=False), nn.Tanh()
        )
    def forward(self,z): return self.net(z)


class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(3,64,4,2,1,bias=False), nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(64,128,4,2,1,bias=False), nn.BatchNorm2d(128), nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(128,256,4,2,1,bias=False), nn.BatchNorm2d(256), nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(256,512,4,2,1,bias=False), nn.BatchNorm2d(512), nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(512,1,4,1,0,bias=False), nn.Sigmoid()
        )
    def forward(self,x): return self.net(x).view(-1)


netG, netD = Generator().to(device), Discriminator().to(device)
optG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5,0.999))
optD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5,0.999))
criterion = nn.BCELoss()
fixed_noise = torch.randn(64,100,1,1,device=device)


for epoch in range(2):
    for real,_ in loader:
        b = real.size(0); real=real.to(device)
        y1,y0=torch.ones(b,device=device),torch.zeros(b,device=device)


        optD.zero_grad()
        lossD_real=criterion(netD(real),y1)
        fake=netG(torch.randn(b,100,1,1,device=device))
        lossD_fake=criterion(netD(fake.detach()),y0)
        lossD=(lossD_real+lossD_fake); lossD.backward(); optD.step()


        optG.zero_grad()
        lossG=criterion(netD(fake),y1); lossG.backward(); optG.step()

    print(f"Epoch {epoch+1}: LossD {lossD:.3f} LossG {lossG:.3f}")
    with torch.no_grad():
        fakes=netG(fixed_noise).cpu()
    grid=utils.make_grid(fakes,normalize=True)
    plt.figure(figsize=(6,6)); plt.axis("off")
    plt.imshow(np.transpose(grid,(1,2,0))); plt.show()